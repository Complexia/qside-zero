{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_models import ChatOpenAI\n",
    "\n",
    "\n",
    "OPENAI_API_KEY = \"hahaha\" \n",
    "\n",
    "llm = ChatOpenAI(openai_api_key=OPENAI_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Langsmith can help with testing in the following ways:\\n\\n1. Test Automation: Langsmith can generate test scripts automatically, reducing the manual effort required for writing test cases. It can create a wide range of test scenarios and generate test data efficiently.\\n\\n2. Test Coverage: Langsmith can analyze the codebase and identify areas that are not adequately covered by tests. It can suggest additional test cases to improve the overall test coverage.\\n\\n3. Bug Detection: Langsmith can analyze the code and identify potential bugs or vulnerabilities. It can detect common coding mistakes, such as null pointer exceptions, resource leaks, or concurrency issues, helping to prevent them from occurring during the testing phase.\\n\\n4. Test Prioritization: Langsmith can prioritize the execution of test cases based on various factors, such as code changes, risk analysis, or critical functionality. It helps in optimizing the testing process by ensuring that the most critical test cases are executed first.\\n\\n5. Test Data Generation: Langsmith can generate diverse and comprehensive test data, including edge cases, invalid inputs, and boundary values, which can improve the effectiveness of testing. It reduces the effort required to manually create test data.\\n\\n6. Test Oracles: Langsmith can analyze the expected behavior of the system and generate test oracles, which help in determining whether the system is functioning correctly. It can automatically generate expected outputs for given inputs, facilitating the comparison of actual and expected results during testing.\\n\\n7. Test Maintenance: Langsmith can assist in maintaining the automated test suite by automatically updating test scripts when there are changes in the codebase. It reduces the effort required to keep the test suite up-to-date and ensures that tests remain relevant.\\n\\nOverall, Langsmith helps in improving the efficiency, effectiveness, and accuracy of the testing process by automating various aspects and providing intelligent analysis and suggestions.')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"how can langsmith help with testing?\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Langsmith can be a valuable tool for testing in several ways:\\n\\n1. Test Case Generation: Langsmith can automatically generate test cases based on the specifications of your software. By providing it with a formal specification or requirements document, Langsmith can generate a suite of test cases that cover various scenarios and edge cases. This can help ensure thorough test coverage and reduce the manual effort required to create test cases.\\n\\n2. Test Data Generation: Generating realistic and diverse test data can be time-consuming and challenging. Langsmith can help by automatically generating test data that covers a wide range of input values, ensuring that your tests cover different scenarios and potential issues. This can help identify bugs and vulnerabilities that may go unnoticed with limited or unrealistic test data.\\n\\n3. Test Oracles: Langsmith can assist in defining test oracles, which are mechanisms to determine if the system under test behaves correctly or not. By specifying the expected outcomes or behaviors for each test case, Langsmith can automatically compare the actual outputs of the system with the expected ones, aiding in the identification of discrepancies and potential bugs.\\n\\n4. Test Automation: Langsmith can be integrated with test automation frameworks to automate the execution of test cases. By providing test inputs and expected outputs, Langsmith can automatically run the tests and check if the actual outputs match the expected ones. This can save time and effort compared to manual testing and enable continuous integration and deployment processes.\\n\\n5. Test Coverage Analysis: Langsmith can analyze the coverage of your test suite to identify any gaps or areas that are not adequately covered. It can provide insights into which parts of the system have been tested and which have not. This can help prioritize testing efforts and ensure comprehensive coverage of critical functionalities.\\n\\nOverall, Langsmith can enhance the testing process by automating repetitive tasks, generating test cases and data, validating expected outcomes, and providing insights into test coverage. This can lead to more efficient and effective testing, ultimately improving the quality and reliability of your software.'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are world class technical documentation writer.\"),\n",
    "    (\"user\", \"{input}\")\n",
    "])\n",
    "\n",
    "chain = prompt | llm | output_parser\n",
    "\n",
    "chain.invoke({\"input\": \"how can langsmith help with testing?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "loader = WebBaseLoader(\"https://docs.smith.langchain.com/overview\")\n",
    "\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "#Our sentences we like to encode\n",
    "sentences = ['This framework generates embeddings for each input sentence',\n",
    "    'Sentences are passed as a list of string.',\n",
    "    'The quick brown fox jumps over the lazy dog.']\n",
    "\n",
    "#Sentences are encoded by calling model.encode()\n",
    "#embeddings = model.encode(sentences)\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<langchain_community.vectorstores.docarray.in_memory.DocArrayInMemorySearch object at 0x126b22d50>\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.vectorstores import DocArrayInMemorySearch\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter()\n",
    "documents = text_splitter.split_documents(docs)\n",
    "vector = DocArrayInMemorySearch.from_documents(documents, embeddings)\n",
    "print(vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\"\"\"Answer the following question based only on the provided context:\n",
    "\n",
    "<context>\n",
    "{context}\n",
    "</context>\n",
    "\n",
    "Question: {input}\"\"\")\n",
    "\n",
    "document_chain = create_stuff_documents_chain(llm, prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_retrieval_chain\n",
    "\n",
    "retriever = vector.as_retriever()\n",
    "retrieval_chain = create_retrieval_chain(retriever, document_chain)\n",
    "\n",
    "response = retrieval_chain.invoke({\"input\": \"how can langsmith help with testing?\"})\n",
    "print(response[\"answer\"])\n",
    "\n",
    "# LangSmith offers several features that can help with testing:..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_history_aware_retriever\n",
    "from langchain_core.prompts import MessagesPlaceholder\n",
    "\n",
    "# First we need a prompt that we can pass into an LLM to generate this search query\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "    (\"user\", \"{input}\"),\n",
    "    (\"user\", \"Given the above conversation, generate a search query to look up in order to get information relevant to the conversation\")\n",
    "])\n",
    "retriever_chain = create_history_aware_retriever(llm, retriever, prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "\n",
    "chat_history = [HumanMessage(content=\"Can LangSmith help test my LLM applications?\"), AIMessage(content=\"Yes!\")]\n",
    "retriever_chain.invoke({\n",
    "    \"chat_history\": chat_history,\n",
    "    \"input\": \"Tell me how\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"Answer the user's questions based on the below context:\\n\\n{context}\"),\n",
    "    MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "    (\"user\", \"{input}\"),\n",
    "])\n",
    "document_chain = create_stuff_documents_chain(llm, prompt)\n",
    "\n",
    "retrieval_chain = create_retrieval_chain(retriever_chain, document_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_history = [HumanMessage(content=\"Can LangSmith help test my LLM applications?\"), AIMessage(content=\"Yes!\")]\n",
    "retrieval_chain.invoke({\n",
    "    \"chat_history\": chat_history,\n",
    "    \"input\": \"Tell me how\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools.retriever import create_retriever_tool\n",
    "\n",
    "retriever_tool = create_retriever_tool(\n",
    "    retriever,\n",
    "    \"langsmith_search\",\n",
    "    \"Search for information about LangSmith. For any questions about LangSmith, you must use this tool!\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "import os\n",
    "\n",
    "os.environ[\"TAVILY_API_KEY\"] = \"suck it\"\n",
    "TAVILY_API_KEY = \"suck it\"\n",
    "\n",
    "search = TavilySearchResults()\n",
    "\n",
    "tools = [retriever_tool, search]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is prompt: input_variables=['agent_scratchpad', 'input'] input_types={'chat_history': typing.List[typing.Union[langchain_core.messages.ai.AIMessage, langchain_core.messages.human.HumanMessage, langchain_core.messages.chat.ChatMessage, langchain_core.messages.system.SystemMessage, langchain_core.messages.function.FunctionMessage, langchain_core.messages.tool.ToolMessage]], 'agent_scratchpad': typing.List[typing.Union[langchain_core.messages.ai.AIMessage, langchain_core.messages.human.HumanMessage, langchain_core.messages.chat.ChatMessage, langchain_core.messages.system.SystemMessage, langchain_core.messages.function.FunctionMessage, langchain_core.messages.tool.ToolMessage]]} messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='You are a helpful assistant')), MessagesPlaceholder(variable_name='chat_history', optional=True), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='{input}')), MessagesPlaceholder(variable_name='agent_scratchpad')]\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain import hub\n",
    "from langchain.agents import create_openai_functions_agent\n",
    "from langchain.agents import AgentExecutor\n",
    "\n",
    "# Get the prompt to use - you can modify this!\n",
    "prompt = hub.pull(\"hwchase17/openai-functions-agent\")\n",
    "print(\"This is prompt:\", prompt)\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
    "agent = create_openai_functions_agent(llm, tools, prompt)\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mNow that you have access to the LangSmith search tool and the Tavily search engine, you can use them to find information and answer any questions you may have. \n",
      "\n",
      "If you have any specific queries or topics you would like to search for, please let me know and I will assist you in using the tools effectively.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'and now?',\n",
       " 'output': 'Now that you have access to the LangSmith search tool and the Tavily search engine, you can use them to find information and answer any questions you may have. \\n\\nIf you have any specific queries or topics you would like to search for, please let me know and I will assist you in using the tools effectively.'}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\"input\": \"and now?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `tavily_search_results_json` with `{'query': 'weather in San Francisco'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3m[{'url': 'https://abc7news.com/bay-area-rain-forecast-storm-timeline-california-weather/14260083/', 'content': \"WATCH LIVE TIMELINE: Rain returns to Bay Area forecast with Sierra snow in 1st week of 2024  SAN FRANCISCO (KGO) -- After a dry New Year's, rain is back in the forecast for the first week of 2024. The Bay Area  2024. The Bay Area will see rain Tuesday night and an isolated shower on Wednesday morning. Thursday is a sunny and dry  is a sunny and dry day but showers return Friday evening and linger into the day Saturday.SAN FRANCISCO (KGO) -- After a dry New Year's, rain is back in the forecast for the first week of 2024. The Bay Area will see rain Tuesday night and an isolated shower on Wednesday morning ...\"}, {'url': 'https://hoodline.com/2024/01/san-francisco-bay-area-faces-rapid-weather-shift-with-rain-winds-and-small-craft-advisories/', 'content': 'San Francisco Bay Area Faces Rapid Weather Shift with Rain, Winds, and Small Craft Advisories  Residents can look forward to a brief respite as the detailed forecast predicts a gradual transition to sunny skies  San Francisco Bay Area residents should brace for a rapid weather shift today, as morning rain showers give way to  reach the peninsula between 9:30-10:00 AM pic.twitter.com/Fox6qYcuncBy Tony Ng. Published on January 03, 2024. San Francisco Bay Area residents should brace for a rapid weather shift today, as morning rain showers give way to breezy northerly winds this afternoon ...'}]\u001b[0m\u001b[32;1m\u001b[1;3mThe weather in San Francisco is currently rainy. There will be rain on Tuesday night and an isolated shower on Wednesday morning. Thursday will be sunny and dry, but showers will return on Friday evening and linger into Saturday. You can find more information about the weather in San Francisco [here](https://abc7news.com/bay-area-rain-forecast-storm-timeline-california-weather/14260083/) and [here](https://hoodline.com/2024/01/san-francisco-bay-area-faces-rapid-weather-shift-with-rain-winds-and-small-craft-advisories/).\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'what is the weather in SF?',\n",
       " 'output': 'The weather in San Francisco is currently rainy. There will be rain on Tuesday night and an isolated shower on Wednesday morning. Thursday will be sunny and dry, but showers will return on Friday evening and linger into Saturday. You can find more information about the weather in San Francisco [here](https://abc7news.com/bay-area-rain-forecast-storm-timeline-california-weather/14260083/) and [here](https://hoodline.com/2024/01/san-francisco-bay-area-faces-rapid-weather-shift-with-rain-winds-and-small-craft-advisories/).'}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\"input\": \"what is the weather in SF?\"})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python-backend-6o6gDVfZ-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
